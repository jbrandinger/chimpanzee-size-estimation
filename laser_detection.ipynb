{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ac0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e2b793d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04a25518",
   "metadata": {},
   "source": [
    "# This part requires detectron2 installation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471432a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mdetectron2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a925b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fa693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import shutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afdb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b45fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assign directory\n",
    "#update paths accordingly\n",
    "\n",
    "path = Path('Downloads/chimp/sample')\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for file_ind, file in enumerate(os.listdir(path)):\n",
    "    file_name = os.path.join(path,file)\n",
    "    if os.path.isfile(file_name):\n",
    "        #print(file_name)\n",
    "        im = cv2.imread(file_name)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        outputs = predictor(im)\n",
    "        \n",
    "        \n",
    "        \n",
    "        mask= outputs['instances'].get('pred_masks')\n",
    "        mask= mask.to('cpu')\n",
    "        \n",
    "        pclass= outputs['instances'].get('pred_classes')\n",
    "        pclass=pclass.to('cpu').numpy()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        h,w,c = im.shape\n",
    "        out = np.zeros((h,w,1),dtype='int64')\n",
    "\n",
    "        for i, j in enumerate(mask):\n",
    "            if pclass[i]==21:\n",
    "                f = mask[i]\n",
    "                f = np.expand_dims(f,axis=2)\n",
    "                f = np.where(f==True, 1, 0)\n",
    "                out += f\n",
    "        trace = np.where(out!=0, im, 0)\n",
    "        trace = cv2.cvtColor(trace, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        #np_arr = mask.cpu().detach().numpy()\n",
    "        #trace = np_arr.reshape(([np_arr.shape[1],np_arr.shape[2],-1]))\n",
    "        #trace = np.where(trace==True, im, 0)\n",
    "        #print(trace)\n",
    "        \n",
    "        new_folder = 'Downloads/mask_result_updated2.0'\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.makedirs(new_folder)\n",
    "        cv2.imwrite(new_folder+'/'+file,trace)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8793fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic=cv2.imread(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de37600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.functional as F\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import shutil, os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee656d",
   "metadata": {},
   "source": [
    "# Start running from here: Provide, masked segmentation output as input image. This can be obtained either via detectron2 or SegmentAnthing (SAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.functional as F\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import shutil, os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a5310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required module\n",
    "import os\n",
    "from skimage.feature import blob_log\n",
    "# assign directory\n",
    "path = Path('/home/obafemi/Downloads/mask_result_updated2.0') #the path to masked image folder (SAM or detectron2) update path accordingly\n",
    "path2 = Path('/media/obafemi/New Volume/chimp/sample') #path to source image folder, update accordingly\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for file_ind, file in enumerate(os.listdir(path)):\n",
    "    file_name = os.path.join(path,file)\n",
    "    full_im = os.path.join(path2,file)\n",
    "    #f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(file_name):\n",
    "        img = cv2.imread(file_name)\n",
    "        img2 = cv2.imread(full_im)   \n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img = cv2.resize(img,(2000,2000))\n",
    "        hsv_frame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) #convert from BGR to HSV \n",
    "\n",
    "        low_green = np.array([55, 110, 110])  #low_green values for green mask\n",
    "        high_green = np.array([65, 255, 255]) #high_green values for green mask\n",
    "        green_mask = cv2.inRange(hsv_frame, low_green, high_green) #performs basic threshold\n",
    "        green = cv2.bitwise_and(img, img, mask=green_mask)#performs bitwise and operation\n",
    "        #plt.imshow(green)\n",
    "        g = green[:,:,1] #extracts the green channel\n",
    "       # green = cv2.cvtColor(green, cv2.COLOR_BGR2GRAY)\n",
    "        #ret, thresh = cv2.threshold(g, 220,255,cv2.THRESH_BINARY)\n",
    "        blur = cv2.GaussianBlur(g,(25,25),0) #adds blurring for smoothing\n",
    "        ret3,thresh = cv2.threshold(blur,210,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) #thresholding technique - pixel values <210 turn to 0, pixel values >210 turn to 255\n",
    "        \n",
    "        #ret, thresh = cv2.threshold(g, 250,255,cv2.THRESH_BINARY) testing a different thresholding technique\n",
    "        #th3 = cv2.dilate(thresh,(5,5),iterations=35)\n",
    "        \n",
    "        \n",
    "        thresh = cv2.dilate(thresh,(5,5),iterations=28) #adds dilation to enlarge dots a bit can be tuned with the arguments\n",
    "\n",
    "        #thresh = cv2.dilate(thresh,(5,7),iterations=35)\n",
    "       # plt.imshow(thresh, cmap='gray')\n",
    "       # fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "        #ax[0].set_title('Binary Thresholding',fontsize=15)\n",
    "        #ax[0].imshow(thresh,cmap='gray')\n",
    "\n",
    "\n",
    "\n",
    "        blobs = blob_log(thresh, max_sigma=50, threshold=0.15) # blob detection\n",
    "        count =0\n",
    "        if blobs.size != 0:  #checks if a blob was found\n",
    "           # ax[1].imshow(thresh, cmap='gray')\n",
    "            for blob in blobs[:2,:]:\n",
    "                y, x, area = blob\n",
    "                if area>1:   #checks for area of blob\n",
    "                   \n",
    "                    count +=1\n",
    "\n",
    "                    result1 = cv2.circle(img2, (int(x),int(y)),12,(0,0,255),-1) # draws circles on detected blob\n",
    "                \n",
    "                    new_folder = '/media/obafemi/New Volume/chimp/mask_detection_result4' #folder where you want resulting images stored, update accordinly\n",
    "                    if not os.path.exists(new_folder):\n",
    "                        os.makedirs(new_folder)\n",
    "                \n",
    "                    cv2.imwrite(new_folder+'/'+file,result1)\n",
    "                   \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcad1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
